### üñºÔ∏è Label Distillation Methods

#### 2020
- **[1] Flexible Dataset Distillation: Learn Labels Instead of Images**, NeurIPSW 2020.  
*Ondrej Bohdal, Yongxin Yang, Timothy Hospedales*  
![](https://img.shields.io/badge/LD-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Label_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://meta-learn.github.io/2020/papers/42_paper.pdf"><img src="https://img.shields.io/badge/NeurIPSW-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/ondrejbohdal/label-distillation"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{bohdal2020flexible,
      title={Flexible Dataset Distillation: Learn Labels Instead of Images},
      author={Bohdal, Ondrej and Yang, Yongxin and Hospedales, Timothy M},
      booktitle={4th Workshop on Meta-Learning at NeurIPS 2020},
      year={2020}
    }
    ```

    </details>

#### 2021
- **[2] Soft-label dataset distillation and text dataset distillation**, IJCNN 2021.  
*Ilia Sucholutsky, Matthias Schonlau*  
![](https://img.shields.io/badge/SLDD-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Label_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://ieeexplore.ieee.org/abstract/document/9533769"><img src="https://img.shields.io/badge/IJCNN-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/ilia10000/dataset-distillation"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{sucholutsky2021soft,
      title={Soft-label dataset distillation and text dataset distillation},
      author={Sucholutsky, Ilia and Schonlau, Matthias},
      booktitle={2021 International Joint Conference on Neural Networks (IJCNN)},
      pages={1--8},
      year={2021},
      organization={IEEE}
    }
    ```

    </details>

#### 2022
- **[3] Dataset distillation using neural feature regression**, NeurIPS 2022.  
*Yongchao Zhou, Ehsan Nezhadarya, Jimmy Ba*  
![](https://img.shields.io/badge/FRePo-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Label_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/3fe2a777282299ecb4f9e7ebb531f0ab-Supplemental-Conference.pdf"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/yongchaoz/FRePo"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{zhou2022dataset,
      title={Dataset distillation using neural feature regression},
      author={Zhou, Yongchao and Nezhadarya, Ehsan and Ba, Jimmy},
      journal={Advances in Neural Information Processing Systems},
      volume={35},
      pages={9813--9827},
      year={2022}
    }
    ```

    </details>

#### 2023
- **[4] Scaling Up Dataset Distillation to ImageNet-1K with Constant Memory**, ICML 2023.  
*Justin Cui, Ruochen Wang, Si Si, Cho-Jui Hsieh*  
![](https://img.shields.io/badge/TESLA-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Label_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://proceedings.mlr.press/v202/cui23e/cui23e.pdf"><img src="https://img.shields.io/badge/ICML-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/justincui03/tesla"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{cui2023scaling,
      title={Scaling up dataset distillation to imagenet-1k with constant memory},
      author={Cui, Justin and Wang, Ruochen and Si, Si and Hsieh, Cho-Jui},
      booktitle={International Conference on Machine Learning},
      year={2023}
    }
    ```

    </details>

- **[5]Squeeze, recover and relabel: Dataset condensation at imagenet scale from a new perspective**, NeurIPS 2023.  
*Yin, Zeyuan and Xing, Eric and Shen, Zhiqiang*  
![](https://img.shields.io/badge/SRe2L-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Label_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/e91fb65c6324a984ea9ef39a5b84af04-Paper-Conference.pdf"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://zeyuanyin.github.io/projects/SRe2L"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>


    <details> <summary>BibTex</summary>

    ```bibtex
    @article{yin2024squeeze,
    title={Squeeze, recover and relabel: Dataset condensation at imagenet scale from a new perspective},
    author={Yin, Zeyuan and Xing, Eric and Shen, Zhiqiang},
    journal={Advances in Neural Information Processing Systems},
    volume={36},
    year={2024}
    }
    ```

    </details>

#### 2024
- **[6] Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching**, ICLR 2024.  
*Ziyao Guo, Kai Wang, George Cazenavette, Hui Li, Kaipeng Zhang, Yang You*  
![](https://img.shields.io/badge/DATM-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Label_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://openreview.net/pdf?id=rTBL8OhdhH"><img src="https://img.shields.io/badge/ICLR-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/NUS-HPC-AI-Lab/DATM"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{guo2024lossless,
      title={Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching}, 
      author={Ziyao Guo and Kai Wang and George Cazenavette and Hui Li and Kaipeng Zhang and Yang You},
      year={2024},
      booktitle={The Twelfth International Conference on Learning Representations}
    }
    ```

    </details>

- **[7] A Label is Worth a Thousand Images in Dataset Distillation**, arXiv 2024.  
*Tian Qin, Zhiwei Deng, David Alvarez-Melis*  
![](https://img.shields.io/badge/Soft_Label-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Label_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://arxiv.org/pdf/2406.10485"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/sunnytqin/no-distillation"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{qin2024label,
      title={A Label is Worth a Thousand Images in Dataset Distillation},
      author={Qin, Tian and Deng, Zhiwei and Alvarez-Melis, David},
      journal={arXiv preprint arXiv:2406.10485},
      year={2024}
    }
    ```

    </details>

- **[8] Prioritize Alignment in Dataset Distillation**, arXiv 2024.  
*Zekai Li, Ziyao Guo, Wangbo Zhao, Tianle Zhang, Zhi-Qi Cheng, Samir Khaki, Kaipeng Zhang, Ahmad Sajedi, Konstantinos N Plataniotis, Kai Wang, Yang You*  
![](https://img.shields.io/badge/PAD-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Label_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://arxiv.org/pdf/2408.03360"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/NUS-HPC-AI-Lab/PAD"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{li2024prioritize,
      title={Prioritize Alignment in Dataset Distillation},
      author={Li, Zekai and Guo, Ziyao and Zhao, Wangbo and Zhang, Tianle and Cheng, Zhi-Qi and Khaki, Samir and Zhang, Kaipeng and Sajedi, Ahmad and Plataniotis, Konstantinos N and Wang, Kai and others},
      journal={arXiv preprint arXiv:2408.03360},
      year={2024}
    }

    ```

    </details>

- **[9] Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?**, NeurIPS 2024.  
*Lingao Xiao, Yang He*  
![](https://img.shields.io/badge/LPLD-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Label_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://openreview.net/forum?id=12A1RT1L87"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/he-y/soft-label-pruning-for-dataset-distillation."><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{xiao2024large,
      title={Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?},
      author={Xiao, Lingao and He, Yang},
      booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems}  
    }
    ```

    </details>

- **[10] Label-Augmented Dataset Distillation**, arXiv 2024.  
*Seoungyoon Kang, Youngsun Lim, Hyunjung Shim*  
![](https://img.shields.io/badge/LADD-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Label_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://arxiv.org/pdf/2409.16239"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E" alt="Paper Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{kang2024label,
      title={Label-Augmented Dataset Distillation},
      author={Kang, Seoungyoon and Lim, Youngsun and Shim, Hyunjung},
      journal={arXiv preprint arXiv:2409.16239},
      year={2024}
    }
    ```

    </details>

- **[11] DRUPI: Dataset Reduction Using Privileged Information**, arXiv 2024.  
*Shaobo Wang, Yantai Yang, Shuaiyu Zhang, Chenghao Sun, Weiya Li, Xuming Hu, Linfeng Zhang*  
![](https://img.shields.io/badge/DRUPI-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Label_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://arxiv.org/pdf/2410.01611"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E" alt="Paper Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{wang2024drupi,
      title={DRUPI: Dataset Reduction Using Privileged Information},
      author={Wang, Shaobo and Yang, Yantai and Zhang, Shuaiyu and Sun, Chenghao and Li, Weiya and Hu, Xuming and Zhang, Linfeng},
      journal={arXiv preprint arXiv:2410.01611},
      year={2024}
    }
    ```

    </details>