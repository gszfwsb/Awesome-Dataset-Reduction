### üñºÔ∏è Decoupled Distillation  Methods


- **[1]Squeeze, recover and relabel: Dataset condensation at imagenet scale from a new perspective**
*Yin, Zeyuan and Xing, Eric and Shen, Zhiqiang*  
![](https://img.shields.io/badge/SRe2L-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Decoupled_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://openreview.net/pdf?id=5Fgdk3hZpb"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" 
alt="Paper Badge"></a>
<a href="https://github.com/VILA-Lab/SRe2L"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>


    <details> <summary>BibTex</summary>

    ```bibtex
    @article{yin2024squeeze,
    title={Squeeze, recover and relabel: Dataset condensation at imagenet scale from a new perspective},
    author={Yin, Zeyuan and Xing, Eric and Shen, Zhiqiang},
    journal={Advances in Neural Information Processing Systems},
    volume={36},
    year={2024}
    }
    ```

    </details>

- **[2]Diversified Semantic Distribution Matching for Dataset Distillation**
*Li, Hongcheng and Zhou, Yucan and Gu, Xiaoyan and Li, Bo and Wang, Weiping*  
![](https://img.shields.io/badge/DSDM-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Decoupled_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://openreview.net/forum?id=vtpwJob0L1"><img src="https://img.shields.io/badge/ACM_MM-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/LINs-lab/RDED"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>


    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{li2024diversified,
    title={Diversified Semantic Distribution Matching for Dataset Distillation},
    author={Li, Hongcheng and Zhou, Yucan and Gu, Xiaoyan and Li, Bo and Wang, Weiping},
    booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
    pages={7542--7550},
    year={2024}
    }

    ```

    </details>


- **[3]Generalized large-scale data condensation via various backbone and statistical matching**
*Shao, Shitong and Yin, Zeyuan and Zhou, Muxin and Zhang, Xindong and Shen, Zhiqiang*  
![](https://img.shields.io/badge/GVBSM-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Decoupled_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://openaccess.thecvf.com/content/CVPR2024/html/Shao_Generalized_Large-Scale_Data_Condensation_via_Various_Backbone_and_Statistical_Matching_CVPR_2024_paper.html"><img src="https://img.shields.io/badge/CVPR-Paper-%23D2691E"  alt="Paper Badge"></a>
<a href="https://github.com/shaoshitong/G_VBSM_Dataset_Condensation"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>


    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{shao2024generalized,
    title={Generalized large-scale data condensation via various backbone and statistical matching},
    author={Shao, Shitong and Yin, Zeyuan and Zhou, Muxin and Zhang, Xindong and Shen, Zhiqiang},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages={16709--16718},
    year={2024}
    }
    ```

    </details>

- **[3]Curriculum Dataset Distillation**
*Ma, Zhiheng and Cao, Anjia and Yang, Funing and Wei, Xing*  
![](https://img.shields.io/badge/CUDD-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Decoupled_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://arxiv.org/abs/2405.09150"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arXiv"  alt="Paper Badge"></a>
<a href=""><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>


    <details> <summary>BibTex</summary>

    ```bibtex
    @article{ma2024curriculum,
    title={Curriculum Dataset Distillation},
    author={Ma, Zhiheng and Cao, Anjia and Yang, Funing and Wei, Xing},
    journal={arXiv preprint arXiv:2405.09150},
    year={2024}
    }
    ```

    </details>

- **[4]DELT: A Simple Diversity-driven EarlyLate Training for Dataset Distillation**
*Shen, Zhiqiang and Sherif, Ammar and Yin, Zeyuan and Shao, Shitong*  
![](https://img.shields.io/badge/DELT-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Decoupled_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://arxiv.org/abs/2411.19946"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arXiv"  alt="Paper Badge"></a>
<a href=""><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>


    <details> <summary>BibTex</summary>

    ```bibtex
    @article{shen2024delt,
    title={DELT: A Simple Diversity-driven EarlyLate Training for Dataset Distillation},
    author={Shen, Zhiqiang and Sherif, Ammar and Yin, Zeyuan and Shao, Shitong},
    journal={arXiv preprint arXiv:2411.19946},
    year={2024}
    }
    ```

    </details>

- **[5]Diversity-Driven Synthesis: Enhancing Dataset Distillation through Directed Weight Adjustment**
*Du, Jiawei and Zhang, Xin and Hu, Juncheng and Huang, Wenxin and Zhou, Joey Tianyi*  
![](https://img.shields.io/badge/DWA-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Decoupled_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://arxiv.org/abs/2409.17612"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arXiv"  alt="Paper Badge"></a>
<a href="https://github.com/vila-lab/delt"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>


    <details> <summary>BibTex</summary>

    ```bibtex
    @article{du2024diversity,
    title={Diversity-driven synthesis: Enhancing dataset distillation through directed weight adjustment},
    author={Du, Jiawei and Zhang, Xin and Hu, Juncheng and Huang, Wenxin and Zhou, Joey Tianyi},
    journal={arXiv preprint arXiv:2409.17612},
    year={2024}
    }
    ```

    </details>






- **[6]Elucidating the Design Space of Dataset Condensation**
*Yin, Zeyuan and Xing, Eric and Shen, Zhiqiang*  
![](https://img.shields.io/badge/EDC-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Decoupled_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://nips.cc/virtual/2024/poster/94518"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" 
alt="Paper Badge"></a>
<a href="https://github.com/VILA-Lab/SRe2L"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>


    <details> <summary>BibTex</summary>

    ```bibtex
    @article{yin2024squeeze,
    title={Squeeze, recover and relabel: Dataset condensation at imagenet scale from a new perspective},
    author={Yin, Zeyuan and Xing, Eric and Shen, Zhiqiang},
    journal={Advances in Neural Information Processing Systems},
    volume={36},
    year={2024}
    }
    ```

    </details>

- **[7]Information Compensation: A Fix for Any-scale Dataset Distillation**
*Sun, Peng and Shi, Bei and Shang, Xinyi and Lin, Tao*  
![](https://img.shields.io/badge/LIC-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Decoupled_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://openreview.net/forum?id=2SnmKd1JK4"><img src="https://img.shields.io/badge/ICLRW-Paper-%23D2691E" 
alt="Paper Badge"></a>
<a href=""><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>


    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{
    anonymous2024information,
    title={Information Compensation: A Fix for Any-scale Dataset Distillation},
    author={Anonymous},
    booktitle={ICLR 2024 Workshop on Data-centric Machine Learning Research (DMLR): Harnessing Momentum for Science},
    year={2024},
    url={https://openreview.net/forum?id=2SnmKd1JK4}
    }
    ```

    </details>



- **[8]On the Diversity and Realism of Distilled Dataset:  An Efficient Dataset Distillation Paradigm**
*Yin, Zeyuan and Xing, Eric and Shen, Zhiqiang*  
![](https://img.shields.io/badge/RDED-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Decoupled_Distillation-red) ![](https://img.shields.io/badge/Dataset_Distillation-orange)
<a href="https://openaccess.thecvf.com/content/CVPR2024/html/Sun_On_the_Diversity_and_Realism_of_Distilled_Dataset_An_Efficient_CVPR_2024_paper.html"><img src="https://img.shields.io/badge/CVPR-Paper-%23D2691E"  alt="Paper Badge"></a>
<a href="https://github.com/LINs-lab/RDED"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>


    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{sun2024diversity,
    title={On the diversity and realism of distilled dataset: An efficient dataset distillation paradigm},
    author={Sun, Peng and Shi, Bei and Yu, Daiwei and Lin, Tao},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages={9390--9399},
    year={2024}
    }
    ```

    </details>

