### üñºÔ∏è Active Learning Methods

#### 2021
- **[1] Accelerating deep learning with dynamic data pruning**, arXiv 2021.  
*Ravi S Raju, Kyle Daruwalla, Mikko Lipasti*  
![](https://img.shields.io/badge/Œµ‚Äîgreedy&UCB-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Uncertainty-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://arxiv.org/pdf/2111.12621"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E" alt="Paper Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{raju2021accelerating,
        title={Accelerating deep learning with dynamic data pruning},
        author={Raju, Ravi S and Daruwalla, Kyle and Lipasti, Mikko},
        journal={arXiv preprint arXiv:2111.12621},
        year={2021}
    }
    ```

    </details> 

#### 2024
- **[2] InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning**, ICLR 2024.  
*Ziheng Qin, Kai Wang, Zangwei Zheng, Jianyang Gu, Xiangyu Peng, Zhaopan Xu, Daquan Zhou, Lei Shang, Baigui Sun, Xuansong Xie, Yang You*  
![](https://img.shields.io/badge/InfoBatch-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Loss-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://iclr.cc/virtual/2024/oral/19779"><img src="https://img.shields.io/badge/ICLR-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/NUS-HPC-AI-Lab/InfoBatch"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{qininfobatch,
        title={InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning},
        author={Qin, Ziheng and Wang, Kai and Zheng, Zangwei and Gu, Jianyang and Peng, Xiangyu and Zhou, Daquan and Shang, Lei and Sun, Baigui and Xie, Xuansong and You, Yang and others},
        booktitle={The Twelfth International Conference on Learning Representations}, 
        year={2024}
    }
    ```

    </details> 

- **[3] TED: Accelerate Model Training by Internal Generalization**, arXiv 2024.  
*Jinying Xiao, Ping Li, Jie Nie*  
![](https://img.shields.io/badge/TED-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Loss-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://arxiv.org/pdf/2405.03228"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E" alt="Paper Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{xiao2024ted,
        title={TED: Accelerate Model Training by Internal Generalization},
        author={Xiao, Jinying and Li, Ping and Nie, Jie},
        journal={arXiv preprint arXiv:2405.03228},
        year={2024}
    }
    ```

    </details> 

- **[4] Dataset Growth**, ECCV 2024.  
*Ziheng Qin, Zhaopan Xu, Yukun Zhou, Zangwei Zheng, Zebang Cheng, Hao Tang, Lei Shang, Baigui Sun, Xiaojiang Peng, Radu Timofte, Hongxun Yao, Kai Wang, Yang You*  
![](https://img.shields.io/badge/InfoGrowth-blue) ![](https://img.shields.io/badge/Multimodal-green) ![](https://img.shields.io/badge/Probability-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01370.pdf"><img src="https://img.shields.io/badge/ECCV-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/NUS-HPC-AI-Lab/InfoGrowth"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{qin2024datasetgrowth,
        title={Dataset Growth}, 
        author={Ziheng Qin and Zhaopan Xu and Yukun Zhou and Zangwei Zheng and Zebang Cheng and Hao Tang and Lei Shang and Baigui Sun and Xiaojiang Peng and Radu Timofte and Hongxun Yao and Kai Wang and Yang You},
        booktitle={ECCV},
        year={2024}
    }
    ```

    </details> 

- **[5] EMP: Enhance Memory in Data Pruning**, arXiv 2024.  
*Jinying Xiao, Ping Li, Jie Nie, Zhe Tang*  
![](https://img.shields.io/badge/EMP-blue) ![](https://img.shields.io/badge/Image_Classification&Contrastive_Learning-green) ![](https://img.shields.io/badge/Loss+Entropy-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://arxiv.org/pdf/2408.16031"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/xiaojinying/EMP"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{xiao2024emp,
        title={EMP: Enhance Memory in Data Pruning},
        author={Xiao, Jinying and Li, Ping and Nie, Jie and Tang, Zhe},
        journal={arXiv preprint arXiv:2408.16031},
        year={2024}
    }
    ```

    </details> 

- **[6] Dynamic Data Pruning for Automatic Speech Recognition**, ISCA 2024.  
*Qiao Xiao, Pingchuan Ma, Adriana Fernandez-Lopez, Boqian Wu, Lu Yin, Stavros Petridis, Mykola Pechenizkiy, Maja Pantic, Decebal Constantin Mocanu, Shiwei Liu*  
![](https://img.shields.io/badge/DDP‚ÄîASR-blue) ![](https://img.shields.io/badge/Automatic_Speech_Recognitio-green) ![](https://img.shields.io/badge/Loss-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://www.isca-archive.org/interspeech_2024/xiao24b_interspeech.pdf"><img src="https://img.shields.io/badge/ISCA-Paper-%23D2691E" alt="Paper Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{xiao2024dynamic,
        title={Dynamic Data Pruning for Automatic Speech Recognition},
        author={Xiao, Qiao and Ma, Pingchuan and Fernandez-Lopez, Adriana and Wu, Boqian and Yin, Lu and Petridis, Stavros and Pechenizkiy, Mykola and Pantic, Maja and Mocanu, Decebal C and Liu, Shiwei},
        booktitle={The 25th Interspeech Conference},
        year={2024}
    }
    ```

    </details> 

- **[7] Accelerating Augmentation Invariance Pretraining**, NeurIPS 2024.  
*Jinhong Lin, Cheng-En Wu, Yibing Wei, Pedro Morgado*  
![](https://img.shields.io/badge/AAIP-blue) ![](https://img.shields.io/badge/Contrastive_Learning-green) ![](https://img.shields.io/badge/Token&Patch-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://neurips.cc/virtual/2024/poster/94817"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{linaccelerating,
        title={Accelerating Augmentation Invariance Pretraining},
        author={Lin, Jinhong and Wu, Cheng-En and Wei, Yibing and Morgado, Pedro},
        booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems}, 
        year={2024}
    }
    ```

    </details> 

- **[8] HEPrune: Fast Private Training of Deep Neural Networks With Encrypted Data Pruning**, NeurIPS 2024.  
*Yancheng Zhang, Mengxin Zheng, Yuzhang Shang, Xun Chen, Qian Lou*  
![](https://img.shields.io/badge/HEPrune-blue) ![](https://img.shields.io/badge/Private_Training-green) ![](https://img.shields.io/badge/Error-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://neurips.cc/virtual/2024/poster/93046"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/UCF-Lou-Lab-PET/Private-Data-Prune"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{zhangheprune,
        title={HEPrune: Fast Private Training of Deep Neural Networks With Encrypted Data Pruning},
        author={Zhang, Yancheng and Zheng, Mengxin and Shang, Yuzhang and Chen, Xun and Lou, Qian},
        booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems}, 
        year={2024}
    }
    ```

    </details> 

- **[9] GDeR: Safeguarding Efficiency, Balancing, and Robustness via Prototypical Graph Pruning**, NeurIPS 2024.  
*Guibin Zhang, Haonan Dong, Yuchen Zhang, Zhixun Li, Dingshuo Chen, Kai Wang, Tianlong Chen, Yuxuan Liang, Dawei Cheng, Kun Wang*  
![](https://img.shields.io/badge/GDeR-blue) ![](https://img.shields.io/badge/Graph_Classification-green) ![](https://img.shields.io/badge/Probability-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://neurips.cc/virtual/2024/poster/95389"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/ins1stenc3/GDeR"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{zhanggder,
        title={GDeR: Safeguarding Efficiency, Balancing, and Robustness via Prototypical Graph Pruning},
        author={Zhang, Guibin and Dong, Haonan and Zhang, Yuchen and Li, Zhixun and Chen, Dingshuo and Wang, Kai and Chen, Tianlong and Liang, Yuxuan and Cheng, Dawei and Wang, Kun},
        booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems}, 
        year={2024}
    }
    ```

    </details> 

- **[10] Beyond Efficiency: Molecular Data Pruning for Enhanced Generalization**, NeurIPS 2024.  
*Dingshuo Chen, Zhixun Li, Yuyan Ni, Guibin Zhang, Ding Wang, Qiang Liu, Shu Wu, Jeffrey Xu Yu, Liang Wang*  
![](https://img.shields.io/badge/MolPeg-blue) ![](https://img.shields.io/badge/Molecular_Tasks-green) ![](https://img.shields.io/badge/Error-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://neurips.cc/virtual/2024/poster/95914"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{chenbeyond,
        title={Beyond Efficiency: Molecular Data Pruning for Enhanced Generalization},
        author={Chen, Dingshuo and Li, Zhixun and Ni, Yuyan and Zhang, Guibin and Wang, Ding and Liu, Qiang and Wu, Shu and Yu, Jeffrey Xu and Wang, Liang},
        booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems}, 
        year={2024}
    }
    ```

    </details> 

- **[11] Efficient Training Acceleration via Sample-Wise Dynamic Probabilistic Pruning**, SPL 2024.  
*Feicheng Huang, Wenbo Zhou, Yue Huang, Xinghao Ding*  
![](https://img.shields.io/badge/SwDPP-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Probability-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://ieeexplore.ieee.org/abstract/document/10723806"><img src="https://img.shields.io/badge/SPL-Paper-%23D2691E" alt="Paper Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{huang2024efficient,
        title={Efficient Training Acceleration via Sample-wise Dynamic Probabilistic Pruning},
        author={Huang, Feicheng and Zhou, Wenbo and Huang, Yue and Ding, Xinghao},
        journal={IEEE Signal Processing Letters},
        year={2024}
    }
    ```

    </details> 

- **[12] SCAN: Bootstrapping Contrastive Pre-training for Data Efficiency**, arXiv 2024.  
*Yangyang Guo, Mohan Kankanhalli*  
![](https://img.shields.io/badge/SCAN-blue) ![](https://img.shields.io/badge/Contrastive_Learning-green) ![](https://img.shields.io/badge/Loss-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://arxiv.org/pdf/2411.09126"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/guoyang9/SCAN"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{guo2024scan,
        title={SCAN: Bootstrapping Contrastive Pre-training for Data Efficiency},
        author={Guo, Yangyang and Kankanhalli, Mohan},
        journal={arXiv preprint arXiv:2411.09126},
        year={2024}
    }
    ```

    </details> 

- **[13] Language Model-Driven Data Pruning Enables Efficient Active Learning**, arXiv 2024.  
*Abdul Hameed Azeemi, Ihsan Ayyub Qazi, Agha Ali Raza*  
![](https://img.shields.io/badge/ActivePrune-blue) ![](https://img.shields.io/badge/Text_Analytics-green) ![](https://img.shields.io/badge/Perplexity-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://arxiv.org/pdf/2410.04275"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E" alt="Paper Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{azeemi2024language,
        title={Language Model-Driven Data Pruning Enables Efficient Active Learning},
        author={Azeemi, Abdul Hameed and Qazi, Ihsan Ayyub and Raza, Agha Ali},
        journal={arXiv preprint arXiv:2410.04275},
        year={2024}
    }
    ```

    </details> 
