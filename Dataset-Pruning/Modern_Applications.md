### üñºÔ∏è Modern Applications

#### üéØ Foundation Models


#### üéØ Embodied AI


#### üéØ Continual Learning
##### 2020
- **[1] Coresets via bilevel optimization for continual learning and streaming**, NeurIPS 2020.  
*Zal√°n Borsos, Mojm√≠r Mutn√Ω, Andreas Krause*  
![](https://img.shields.io/badge/Bilevel‚ÄîCoreset-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Optimization-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/aa2a77371374094fe9e0bc1de3f94ed9-Paper.pdf"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/zalanborsos/bilevel_coresets"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{borsos2020coresets,
    title={Coresets via bilevel optimization for continual learning and streaming},
    author={Borsos, Zal{\'a}n and Mutny, Mojmir and Krause, Andreas},
    journal={Advances in neural information processing systems},
    year={2020}
    }
    ```

    </details> 

##### 2024
- **[2] Structural-Entropy-Based Sample Selection for Efficient and Effective Learning**, arXiv 2024.  
*Tianchi Xie, Jiangning Zhu, Guozu Ma, Minzhi Lin, Wei Chen, Weikai Yang, Shixia Liu*  
![](https://img.shields.io/badge/SES-blue) ![](https://img.shields.io/badge/Image_Classification&Text_Classification&Object_Detection&Visual_Question,-green) ![](https://img.shields.io/badge/Entropy-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://arxiv.org/pdf/2410.02268"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arXiv" alt="Paper Badge"></a>
<a href="https://anonymous.4open.science/r/SE-based_sample_selection-575B/"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{xie2024structural,
    title={Structural-Entropy-Based Sample Selection for Efficient and Effective Learning},
    author={Xie, Tianchi and Zhu, Jiangning and Ma, Guozu and Lin, Minzhi and Chen, Wei and Yang, Weikai and Liu, Shixia},
    journal={arXiv preprint arXiv:2410.02268},
    year={2024}
    }
    ```

    </details> 

#### üéØ Neural Architecture Search
##### 2023
- **[3] Dataset Pruning: Reducing Training Data by Examining Generalization Influence**, ICLR 2023.  
*Shuo Yang, Zeke Xie, Hanyu Peng, Min Xu, Mingming Sun, Ping Li*  
![](https://img.shields.io/badge/Optimization‚Äîbased-blue) ![](https://img.shields.io/badge/Image_Classification-green) ![](https://img.shields.io/badge/Optimization-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://iclr.cc/virtual/2023/poster/12019"><img src="https://img.shields.io/badge/ICLR-Paper-%23D2691E" alt="Paper Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{yang2023dataset,
    title={Dataset Pruning: Reducing Training Data by Examining Generalization Influence},
    author={Yang, Shuo and Xie, Zeke and Peng, Hanyu and Xu, Min and Sun, Mingming and Li, Ping},
    booktitle={The Eleventh International Conference on Learning Representations}, 
    year={2023}
    }
    ```

    </details> 

#### üéØ Privacy
##### 2024
- **[4] HEPrune: Fast Private Training of Deep Neural Networks With Encrypted Data Pruning**, NeurIPS 2024.  
*Yancheng Zhang, Mengxin Zheng, Yuzhang Shang, Xun Chen, Qian Lou*  
![](https://img.shields.io/badge/HEPrune-blue) ![](https://img.shields.io/badge/Private_Training-green) ![](https://img.shields.io/badge/Error-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://neurips.cc/virtual/2024/poster/93046"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/UCF-Lou-Lab-PET/Private-Data-Prune"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{zhang2024heprune,
    title={HEPrune: Fast Private Training of Deep Neural Networks With Encrypted Data Pruning},
    author={Zhang, Yancheng and Zheng, Mengxin and Shang, Yuzhang and Chen, Xun and Lou, Qian},
    booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems}, 
    year={2024}
    }
    ```

    </details> 

#### üéØ Other Data Modalities
##### üìà Graph
##### 2024
- **[5] GDeR: Safeguarding Efficiency, Balancing, and Robustness via Prototypical Graph Pruning**, NeurIPS 2024.  
*Guibin Zhang, Haonan Dong, Yuchen Zhang, Zhixun Li, Dingshuo Chen, Kai Wang, Tianlong Chen, Yuxuan Liang, Dawei Cheng, Kun Wang*  
![](https://img.shields.io/badge/GDeR-blue) ![](https://img.shields.io/badge/Graph_Classification-green) ![](https://img.shields.io/badge/Probability-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://neurips.cc/virtual/2024/poster/95389"><img src="https://img.shields.io/badge/NeurIPS-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/ins1stenc3/GDeR"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{zhang2024gder,
    title={GDeR: Safeguarding Efficiency, Balancing, and Robustness via Prototypical Graph Pruning},
    author={Zhang, Guibin and Dong, Haonan and Zhang, Yuchen and Li, Zhixun and Chen, Dingshuo and Wang, Kai and Chen, Tianlong and Liang, Yuxuan and Cheng, Dawei and Wang, Kun},
    booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems}, 
    year={2024}
    }
    ```

    </details> 

##### üó£Ô∏è Speech
##### 2024
- **[6] Dynamic Data Pruning for Automatic Speech Recognition**, ISCA 2024.  
*Qiao Xiao, Pingchuan Ma, Adriana Fernandez-Lopez, Boqian Wu, Lu Yin, Stavros Petridis, Mykola Pechenizkiy, Maja Pantic, Decebal Constantin Mocanu, Shiwei Liu*  
![](https://img.shields.io/badge/DDP‚ÄîASR-blue) ![](https://img.shields.io/badge/Automatic_Speech_Recognitio-green) ![](https://img.shields.io/badge/Loss-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://www.isca-archive.org/interspeech_2024/xiao24b_interspeech.pdf"><img src="https://img.shields.io/badge/ISCA-Paper-%23D2691E" alt="Paper Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{xiao2024dynamic,
    title={Dynamic Data Pruning for Automatic Speech Recognition},
    author={Xiao, Qiao and Ma, Pingchuan and Fernandez-Lopez, Adriana and Wu, Boqian and Yin, Lu and Petridis, Stavros and Pechenizkiy, Mykola and Pantic, Maja and Mocanu, Decebal C and Liu, Shiwei},
    booktitle={The 25th Interspeech Conference},
    year={2024}
    }
    ```

    </details> 

##### üíª Multimodal
##### 2023
- **[7] Too Large; Data Reduction for Vision-Language Pre-Training**, ICCV 2023.  
*Alex Jinpeng Wang, Kevin Qinghong Lin, David Junhao Zhang, Stan Weixian Lei, Mike Zheng Shou*  
![](https://img.shields.io/badge/TL;DR-blue) ![](https://img.shields.io/badge/Multimodal-green) ![](https://img.shields.io/badge/Cluster-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Too_Large_Data_Reduction_for_Vision-Language_Pre-Training_ICCV_2023_paper.pdf"><img src="https://img.shields.io/badge/ICCV-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/showlab/datacentric.vlp"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{wang2023too,
    title={Too large; data reduction for vision-language pre-training},
    author={Wang, Alex Jinpeng and Lin, Kevin Qinghong and Zhang, David Junhao and Lei, Stan Weixian and Shou, Mike Zheng},
    booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
    year={2023}
    }
    ```

    </details> 

##### 2024
- **[8] Dataset Growth**, ECCV 2024.  
*Ziheng Qin, Zhaopan Xu, Yukun Zhou, Zangwei Zheng, Zebang Cheng, Hao Tang, Lei Shang, Baigui Sun, Xiaojiang Peng, Radu Timofte, Hongxun Yao, Kai Wang, Yang You*  
![](https://img.shields.io/badge/InfoGrowth-blue) ![](https://img.shields.io/badge/Multimodal-green) ![](https://img.shields.io/badge/Probability-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01370.pdf"><img src="https://img.shields.io/badge/ECCV-Paper-%23D2691E" alt="Paper Badge"></a>
<a href="https://github.com/NUS-HPC-AI-Lab/InfoGrowth"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @inproceedings{qin2024dataset,
    title={Dataset Growth}, 
    author={Ziheng Qin and Zhaopan Xu and Yukun Zhou and Zangwei Zheng and Zebang Cheng and Hao Tang and Lei Shang and Baigui Sun and Xiaojiang Peng and Radu Timofte and Hongxun Yao and Kai Wang and Yang You},
    booktitle={ECCV},
    year={2024}
    }
    ```

    </details> 

##### üìñ Text
##### 2024
- **[9] EMP: Enhance Memory in Data Pruning**, arXiv 2024.  
*Jinying Xiao, Ping Li, Jie Nie, Zhe Tang*  
![](https://img.shields.io/badge/EMP-blue) ![](https://img.shields.io/badge/Image_Classification&Contrastive_Learning-green) ![](https://img.shields.io/badge/Loss+Entropy-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://arxiv.org/pdf/2408.16031"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arXiv" alt="Paper Badge"></a>
<a href="https://github.com/xiaojinying/EMP"><img src="https://img.shields.io/badge/GitHub-Code-brightgreen?logo=github" alt="Code Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{xiao2024emp,
    title={EMP: Enhance Memory in Data Pruning},
    author={Xiao, Jinying and Li, Ping and Nie, Jie and Tang, Zhe},
    journal={arXiv preprint arXiv:2408.16031},
    year={2024}
    }
    ```

    </details> 

- **[10] Language Model-Driven Data Pruning Enables Efficient Active Learning**, arXiv 2024.  
*Abdul Hameed Azeemi, Ihsan Ayyub Qazi, Agha Ali Raza*  
![](https://img.shields.io/badge/ActivePrune-blue) ![](https://img.shields.io/badge/Text_Analytics-green) ![](https://img.shields.io/badge/Perplexity-red) ![](https://img.shields.io/badge/Dataset_Pruning-orange)
<a href="https://arxiv.org/pdf/2410.04275"><img src="https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arXiv" alt="Paper Badge"></a>
    <details> <summary>BibTex</summary>

    ```bibtex
    @article{azeemi2024language,
    title={Language Model-Driven Data Pruning Enables Efficient Active Learning},
    author={Azeemi, Abdul Hameed and Qazi, Ihsan Ayyub and Raza, Agha Ali},
    journal={arXiv preprint arXiv:2410.04275},
    year={2024}
    }
    ```

    </details> 